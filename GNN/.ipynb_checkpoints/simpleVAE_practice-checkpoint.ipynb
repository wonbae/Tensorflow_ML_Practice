{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"VAE.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "def img_tile(imgs, aspect_ratio=1.0, tile_shape=None, border=1,\n",
    "             border_color=0):\n",
    "    imgs = np.array(imgs)\n",
    "    if imgs.ndim != 3 and imgs.ndim != 4:\n",
    "        raise ValueError('imgs has wrong number of dimensions.')\n",
    "    n_imgs = imgs.shape[0]\n",
    "\n",
    "    # Grid shape\n",
    "    img_shape = np.array(imgs.shape[1:3])\n",
    "    if tile_shape is None:\n",
    "        img_aspect_ratio = img_shape[1] / float(img_shape[0])\n",
    "        aspect_ratio *= img_aspect_ratio\n",
    "        tile_height = int(np.ceil(np.sqrt(n_imgs * aspect_ratio)))\n",
    "        tile_width = int(np.ceil(np.sqrt(n_imgs / aspect_ratio)))\n",
    "        grid_shape = np.array((tile_height, tile_width))\n",
    "    else:\n",
    "        assert len(tile_shape) == 2\n",
    "        grid_shape = np.array(tile_shape)\n",
    "\n",
    "    # Tile image shape\n",
    "    tile_img_shape = np.array(imgs.shape[1:])\n",
    "    tile_img_shape[:2] = (img_shape[:2] + border) * grid_shape[:2] - border\n",
    "\n",
    "    # Assemble tile image\n",
    "    tile_img = np.empty(tile_img_shape)\n",
    "    tile_img[:] = border_color\n",
    "    for i in range(grid_shape[0]):\n",
    "        for j in range(grid_shape[1]):\n",
    "            img_idx = j + i * grid_shape[1]\n",
    "            if img_idx >= n_imgs:\n",
    "                # No more images - stop filling out the grid.\n",
    "                break\n",
    "            img = imgs[img_idx]\n",
    "            yoff = (img_shape[0] + border) * i\n",
    "            xoff = (img_shape[1] + border) * j\n",
    "            tile_img[yoff:yoff + img_shape[0], xoff:xoff + img_shape[1], ...] = img\n",
    "\n",
    "    return tile_img\n",
    "\n",
    "\n",
    "def plot_network_output(data, reconst_data, generated, step):\n",
    "    num = 8\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=3, ncols=num, figsize=(18, 6))\n",
    "    for i in range(num):\n",
    "        ax[(0, i)].imshow(np.squeeze(generated[i]), cmap=plt.cm.gray)\n",
    "        ax[(1, i)].imshow(np.squeeze(data[i]), cmap=plt.cm.gray)\n",
    "        ax[(2, i)].imshow(np.squeeze(reconst_data[i]), cmap=plt.cm.gray)\n",
    "        ax[(0, i)].axis('off')\n",
    "        ax[(1, i)].axis('off')\n",
    "        ax[(2, i)].axis('off')\n",
    "\n",
    "    fig.suptitle('Top: generated | Middle: data | Bottom: recunstructed')\n",
    "#     plt.show()\n",
    "    plt.savefig(IMAGE_DIR + '/{}.png'.format(str(step).zfill(6)))\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "(train_data, train_label), (test_data, test_label) = mnist.load_data()\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of MNIST\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data\n",
    "idx = np.random.randint(0, train_data.shape[0])\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sample_data = train_data[idx]\n",
    "ax1.imshow(sample_data, 'gray');\n",
    "ax2.hist(sample_data, bins=20, range=[0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete summary folder and make it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_DIR = './vae_summary'\n",
    "TRAIN_DIR = SUMMARY_DIR + '/train'\n",
    "TEST_DIR = SUMMARY_DIR + '/test'\n",
    "IMAGE_DIR = SUMMARY_DIR + '/image'\n",
    "\n",
    "if os.path.exists(SUMMARY_DIR):\n",
    "    shutil.rmtree(SUMMARY_DIR)\n",
    "if not os.path.exists(SUMMARY_DIR):\n",
    "    os.makedirs(SUMMARY_DIR)\n",
    "    os.makedirs(TRAIN_DIR)\n",
    "    os.makedirs(TEST_DIR)\n",
    "    os.makedirs(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(inputs, out_channel, name='fc'):\n",
    "    \"\"\"\n",
    "    very simple fully connected layer function\n",
    "\n",
    "    Args:\n",
    "        inputs: a batch of input tensor [batch_size, n]\n",
    "                where n is the number of feature dimension\n",
    "        out_channel: output channel dimension\n",
    "\n",
    "    Returns:\n",
    "        inputs * weights + biases [batch_size, out_channel]\n",
    "    \"\"\"\n",
    "    # in_channel: input channel dimension\n",
    "    # w_shape: shape of weight matrix\n",
    "    # b_shape: shape of bias vector\n",
    "    in_channel = inputs.get_shape().as_list()[1]\n",
    "    w_shape = [in_channel, out_channel]\n",
    "    b_shape = [out_channel]\n",
    "\n",
    "    # Define weight matrix variable, bias vector variable\n",
    "    with tf.variable_scope(name):\n",
    "        # To share the variables you have to use\n",
    "        # a function 'tf.get_variable' instead of 'tf.Variable'\n",
    "        weights = tf.get_variable('weights', shape=w_shape,\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        biases = tf.get_variable('biases', shape=b_shape,\n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        fc = tf.matmul(inputs, weights)\n",
    "        fc = tf.nn.bias_add(fc, biases)\n",
    "\n",
    "        return fc\n",
    "\n",
    "\n",
    "def encoder(x, z_dim):\n",
    "    \"\"\"\n",
    "    build the encoder\n",
    "\n",
    "    Args:\n",
    "        x: a batch of input to the network [batch_size, 28, 28, 1]\n",
    "        z_dim: dimension of the latent variable z\n",
    "\n",
    "    returns:\n",
    "        z_mean: mean of the latent variable [batch_size, n_latent]\n",
    "        z_log_sigma_sq : log sigma squre of the latent variable [batch_size, n_latent]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('encoder') as scope:\n",
    "        \n",
    "        # Vectorize the input x\n",
    "        # Fully connected layer with 256 output units and 'fc1' as its name\n",
    "        # Apply non-linearity function 'relu'\n",
    "        # Fully connected layer with 256 output units and 'fc2' as its name\n",
    "        # Apply non-linearity function 'relu'\n",
    "        # Fully connected layer with z_dim * 2 units and 'fc3' as its name\n",
    "        # split the final tensor into mean and the log sigma square of the latent variable\n",
    "        # Return the final tensors\n",
    "        \n",
    "        return z_mean, z_log_sigma_sq\n",
    "\n",
    "\n",
    "def decoder(z, reuse=False):\n",
    "    \"\"\"\n",
    "    build the decoder\n",
    "\n",
    "    Args:\n",
    "        z: a batch of input to the network [batch_size, n_latent]\n",
    "\n",
    "    Returns:\n",
    "        net: output of the generator [batch_size, 28, 28, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        # Fully connected layer with 256 output units and 'fc1' as its name\n",
    "        # Apply non-linearity function 'relu'\n",
    "        # Fully connected layer with 256 output units and 'fc2' as its name\n",
    "        # Apply non-linearity function 'relu'\n",
    "        # Fully connected layer with 784 output units and 'fc3' as its name\n",
    "        # Apply non-linearity function 'sigmoid'\n",
    "        # Reshape final output to be a proper image file [28, 28, 1]\n",
    "        # Return the final tensor\n",
    "        \n",
    "        \n",
    "        return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reconstrunction_loss = $$-\\Sigma_{i=1}^{D} x_{i}log y_{i} + (1-x_{i})log(1-y_{i}))$$\n",
    "### KL_loss = $$-\\frac{1}{2}\\Sigma_{j=1}^{J}(1+log \\sigma_{j}^2 - \\mu_{j}^2 -\\sigma_{j}^2)$$\n",
    "    \n",
    "### Loss = reconstruction_loss + KL_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(x, reconst_x, z_mean, z_log_sigma_sq, eps=1e-8):\n",
    "    \"\"\"\n",
    "    get loss of GAN\n",
    "\n",
    "    Args:\n",
    "        x: input tensor [batch_size, 28, 28, 1]\n",
    "        reconst_x: reconstructed tensor [batch_size, 28, 28, 1]\n",
    "        z_mean: mean of the latent variable [batch_size, z_dim]\n",
    "        z_log_sigma_sq: log sigma square of the latent variable [batch_size, z_dim]\n",
    "\n",
    "    Returns:\n",
    "        reconst_loss: reconstruction loss\n",
    "        kl_loss: regularization loss\n",
    "    \"\"\"\n",
    "\n",
    "    return reconst_loss, kl_loss\n",
    "\n",
    "\n",
    "def get_next_batch(data, label, batch_size):\n",
    "    \"\"\"\n",
    "    get 'batch_size' amount of data and label randomly\n",
    "\n",
    "    Args:\n",
    "        data: data\n",
    "        label: label\n",
    "        batch_size: # of data to get\n",
    "\n",
    "    Returns:\n",
    "        batch_data: data of 'batch_size'\n",
    "        batch_label: coresponding label of batch_data\n",
    "    \"\"\"\n",
    "    n_data = data.shape[0]\n",
    "    random_idx = random.sample(range(1, n_data), batch_size)\n",
    "\n",
    "    batch_data = data[random_idx]\n",
    "    batch_label = label[random_idx]\n",
    "    return batch_data, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "batch_size = 100\n",
    "z_dim = 2\n",
    "max_step = 20000\n",
    "lr = 0.001\n",
    "beta1 = 0.9\n",
    "\n",
    "# expand the data to be 3 dimensional data.\n",
    "train_data = np.expand_dims(train_data, 3)\n",
    "test_data = np.expand_dims(test_data, 3)\n",
    "\n",
    "############################# Build the model #############################\n",
    "# Define image tensor x placeholder\n",
    "x = tf.placeholder(tf.float32, [batch_size, 28, 28, 1], name='input_x')\n",
    "# Define latent tensor z placeholder\n",
    "z = tf.placeholder(tf.float32, [batch_size, z_dim], name='input_z')\n",
    "\n",
    "# Defin normal distribution (mu=0, sigma=1)\n",
    "\n",
    "# Build encoder\n",
    "\n",
    "# Get epsilon to recover encoded_z\n",
    "\n",
    "# Get encoded_z using z_mean, z_log_sigma_sq, eps\n",
    "\n",
    "# Build decoder with encoded_z which outputs reconst_x\n",
    "# reconst_x is reconstruction of the input data x\n",
    "\n",
    "# Build decoder with placeholder z which outputs sample_x\n",
    "# sample_x is generated data from VAE\n",
    "\n",
    "# Get reconst_loss and kl_loss\n",
    "\n",
    "# Make optimization op\n",
    "opt = tf.train.AdamOptimizer(lr, beta1=beta1)\n",
    "\n",
    "# Make train op for each network\n",
    "train = opt.minimize(loss)\n",
    "\n",
    "# Make initialization op\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Define writer\n",
    "    train_writer = tf.summary.FileWriter(TRAIN_DIR, sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(TEST_DIR)\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Before train the model, shows train data and save it\n",
    "    batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "    train_tiled = img_tile(batch_x, border_color=1.0)\n",
    "    train_tiled = np.squeeze(train_tiled)\n",
    "    print(\"Training data\")\n",
    "    plt.imshow(train_tiled, cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    plt.imsave(IMAGE_DIR + '/train.png', train_tiled, cmap=plt.cm.gray)\n",
    "\n",
    "    samples = []\n",
    "    canvases = []\n",
    "    # Train the model\n",
    "    for step in range(max_step):\n",
    "        batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "        batch_z = np.random.normal(loc=0., scale=1.0, size=[batch_size, z_dim])\n",
    "        \n",
    "        _, reconst_losses, kl_losses = sess.run(\n",
    "            [train, reconst_loss, kl_loss], feed_dict={x: batch_x, z: batch_z})\n",
    "        summary = sess.run(merged, feed_dict={x: batch_x, z: batch_z})\n",
    "        train_writer.add_summary(summary, step)\n",
    "\n",
    "        # Save generarted data to make gif files\n",
    "        if step % 50 == 0:\n",
    "            r_x, s_x = sess.run([reconst_x, sample_x], feed_dict={x: batch_x, z: batch_z})\n",
    "            sample_tiled = img_tile(s_x, border_color=1.0)\n",
    "            sample_tiled = np.squeeze(sample_tiled)\n",
    "            samples.append(sample_tiled)\n",
    "            \n",
    "            nx = ny = 20\n",
    "            x_values = np.linspace(-3, 3, nx)\n",
    "            y_values = np.linspace(-3, 3, ny)\n",
    "            canvas = np.empty((28*ny, 28*nx))\n",
    "            for i, yi in enumerate(x_values):\n",
    "                for j, xi in enumerate(y_values):\n",
    "                    z_mu = np.array([[xi, yi]] * batch_size)\n",
    "                    x_mean = sess.run(sample_x, feed_dict={z: z_mu})\n",
    "                    canvas[(nx - i - 1) * 28:(nx - i) * 28, j * 28:(j + 1) * 28] = x_mean[0].reshape(28, 28)\n",
    "            canvases.append(canvas)\n",
    "\n",
    "        # Log loss and save train data and reconstructed data\n",
    "        if step % 200 == 0:\n",
    "            plot_network_output(batch_x, r_x, s_x, step)\n",
    "            print(\"{} steps |  total_loss: {:.4f}, KL_loss: {:.4f}, reconst_loss: {:.4f}\".format(\n",
    "                step, kl_losses + reconst_losses, kl_losses, reconst_losses))\n",
    "            plt.imshow(sample_tiled, cmap=plt.cm.gray)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "# Make gif files\n",
    "imageio.mimsave(SUMMARY_DIR + '/generated.gif', samples)\n",
    "imageio.mimsave(SUMMARY_DIR + '/canvase.gif', canvases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
